import time
from flask import Flask, Response, jsonify
from bioblend.galaxy import GalaxyInstance
from bioblend.galaxy.tools import ToolClient
import os
from dotenv import load_dotenv

app = Flask(__name__)
load_dotenv()
api_key = os.getenv("API_KEY")
galaxy_url = os.getenv("GALAXY_URL")

gi = GalaxyInstance(url=galaxy_url, key=api_key)
toolClient = ToolClient(gi)

go_enrichment_tool_id = gi.tools.get_tools(name='GOEnrichment')[0]['id']
toolShow = toolClient.show_tool(go_enrichment_tool_id, io_details=True)

histories = gi.histories.get_histories(all=True)

# Get the ids of the sample history, GO files, sample annotation file and sample study file

# The data I used to test this api I obtained from this tutorial:
# https://training.galaxyproject.org/training-material/topics/transcriptomics/tutorials/goenrichment/tutorial.html
# which uses data from Trapnell et al. 2014 https://pubmed.ncbi.nlm.nih.gov/22383036/
# 
# The tutorial provided me with one of the ontology files used (go.obo)
# I also downloaded uberon.owl from https://obofoundry.org/ontology/uberon.html
sample_history_id = ""
ontology_ids = []
sample_annotation_id = ""
sample_study_id = ""

# To load in the sample data from Galaxy, iterate over the list of histories
for history in histories:
    # I am only interested in the sample history I created in Galaxy for this demo
    if history['name'] == 'Sample history':
        # Get a list of datasets in the history
        datasets = gi.histories.show_history(history['id'], contents=True)
        sample_history_id = history['id']
        # Iterate over the list of datasets
        for dataset in datasets:
            if dataset['name'] == 'Sample annotation':
                sample_annotation_id = dataset['id']
            if dataset['name'] == 'Sample study':
                sample_study_id = dataset['id']
            if dataset['extension'] == 'obo' or dataset['extension'] == 'owl':
                ontology_ids.append(dataset['id'])

@app.route('/run-go-enrichment/<int:ontology_num>', methods=['GET'])
def run_go_enrichment(ontology_num):
    # Define the input data for the job
    inputs = {
        'go':{'src': 'hda', 'id': ontology_ids[ontology_num]},
        'annotation':{'src': 'hda', 'id': sample_annotation_id},
        'study':{'src': 'hda', 'id': sample_study_id}
    }
    # Run the job
    results = gi.tools.run_tool(history_id=sample_history_id, tool_id=go_enrichment_tool_id, tool_inputs=inputs)
    preview_image_id = results['outputs'][-1]['id']

    dataset = gi.datasets.show_dataset(preview_image_id)

    # Wait until the dataset is finished loading (there are no asynchronous calls in bioblend)
    while dataset['state'] != 'ok':
        time.sleep(5)
        dataset = gi.datasets.show_dataset(preview_image_id)

    # Download the contents of the dataset
    image_contents = gi.datasets.download_dataset(preview_image_id)
    
    # Save the image to the local machine
    with open("preview.png", "wb") as f:
        f.write(image_contents)
    
    # Return the last image generated by the tool as a preview
    return Response(image_contents, content_type="image/png")

if __name__ == '__main__':
    app.run(debug=True)